# -*- coding: utf-8 -*-
"""Classification_Project_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mm8bP9A9CZ4wM-P7NnZjOrlGLPh9Px-g
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/students - data.csv.csv',)

df.head(5)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['Target'] = encoder.fit_transform(df.Target)

x = df.iloc[:,:-1]
y = df.iloc[:,-1]

x

y

df.isnull().sum()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

df.info()

df.columns

num_cols = ['Marital Status ', 'Application mode', 'Application order', 'Course',
       'Daytime/evening attendance\t', 'Previous qualification',
       'Previous qualification (grade)', 'Nacionality',
       "Mother's qualification", "Father's qualification",
       "Mother's occupation", "Father's occupation", 'Admission grade',
       'Displaced', 'Educational special needs', 'Debtor',
       'Tuition fees up to date', 'Gender', 'Scholarship holder',
       'Age at enrollment', 'International',
       'Curricular units 1st sem (credited)',
       'Curricular units 1st sem (enrolled)',
       'Curricular units 1st sem (evaluations)',
       'Curricular units 1st sem (approved)',
       'Curricular units 1st sem (grade)',
       'Curricular units 1st sem (without evaluations)',
       'Curricular units 2nd sem (credited)',
       'Curricular units 2nd sem (enrolled)',
       'Curricular units 2nd sem (evaluations)',
       'Curricular units 2nd sem (approved)',
       'Curricular units 2nd sem (grade)',
       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',
       'Inflation rate', 'GDP']

from sklearn.preprocessing import RobustScaler

numerical_pipeline = Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),('scaler',RobustScaler())])

prex = ColumnTransformer(
    transformers=[
        ('num_pipeline', numerical_pipeline, num_cols),
    ]
)

x_train = prex.fit_transform(x_train)
x_test = prex.transform(x_test)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
params = {
    'penalty': ('l1', 'l2', 'elasticnet'),
    'C': [0.1,0.01,1,10,100],
    'solver': ('liblinear', 'saga', 'lbfgs', 'newton-cg', 'newton-cholesky', 'sag'),
    'max_iter': [100],
    'multi_class': ('ovr', 'multinomial'),
    'n_jobs': (1, 2, 3, 4)
}

model = LogisticRegression()
grid_model = GridSearchCV(estimator=model, param_grid=params, cv=5,verbose=3,scoring= 'accuracy')
grid_model.fit(x_train,y_train)

grid_model.best_params_

grid_model.best_score_

"""# Decision Tree Classifer"""

from sklearn.tree import DecisionTreeClassifier
params_tree = {
    'criterion': ('gini', 'entropy','log_loss'),
    'splitter': ('best', 'random'),
    'random_state': [1]
}
tree_clf = DecisionTreeClassifier(max_depth=1, random_state=1)
x = df_x.iloc[:,:-1]
y = df_x.iloc[:,-1]
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)

grid_search_1 = GridSearchCV(estimator=tree_clf,param_grid=params_tree,cv=10,verbose=3,scoring='accuracy')
grid_search_1.fit(x_train,y_train)

grid_search_1.best_params_

grid_search_1.best_score_

"""#Support Vector Machine"""

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

num_cols = ['Marital Status ', 'Application mode', 'Application order', 'Course',
       'Daytime/evening attendance\t', 'Previous qualification',
       'Previous qualification (grade)', 'Nacionality',
       "Mother's qualification", "Father's qualification",
       "Mother's occupation", "Father's occupation", 'Admission grade',
       'Displaced', 'Educational special needs', 'Debtor',
       'Tuition fees up to date', 'Gender', 'Scholarship holder',
       'Age at enrollment', 'International',
       'Curricular units 1st sem (credited)',
       'Curricular units 1st sem (enrolled)',
       'Curricular units 1st sem (evaluations)',
       'Curricular units 1st sem (approved)',
       'Curricular units 1st sem (grade)',
       'Curricular units 1st sem (without evaluations)',
       'Curricular units 2nd sem (credited)',
       'Curricular units 2nd sem (enrolled)',
       'Curricular units 2nd sem (evaluations)',
       'Curricular units 2nd sem (approved)',
       'Curricular units 2nd sem (grade)',
       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',
       'Inflation rate', 'GDP']

numerical_pipeline_svm = Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),('scaler',StandardScaler())])

prex_1 = ColumnTransformer(
    transformers=[
        ('num_pipeline',numerical_pipeline_svm,num_cols),
    ]
)

x_svm = df.iloc[:,:-1]
y_svm = df.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_svm,y_svm,test_size=0.3,random_state=50)

x_train = prex_1.fit_transform(x_train)
x_test = prex_1.transform(x_test)

from sklearn.svm import SVC
# Define the parameter grid
params_svm = {
    'C': np.linspace(0.1, 2.0, num=100),  # Extended regularization parameter
    'gamma': np.geomspace(0.1, 1, num=10),  # Extended kernel coefficient
    'kernel': ["linear"],
    'random_state': [1]
}

from sklearn.model_selection import GridSearchCV
grid_svc = GridSearchCV(estimator=svm,param_grid=params_svm,cv=5,verbose=3,scoring='accuracy')

grid_svc.fit(x_train,y_train)

grid_svc.best_params_

grid_svc.best_score_

"""#Naive Bayes Classification"""

from sklearn.naive_bayes import GaussianNB

clf = GaussianNB()

clf.fit(x_train,y_train)

y_pred = clf.predict(x_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))

"""#AdaBoost Classification"""

df_x = df.copy()

df_x.info()

from sklearn.utils import resample

df_x = resample(df_x, replace=True,n_samples=100000, random_state=1)

x_ada = df_x.iloc[:,:-1]
y_ada = df_x.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_ada_train,x_ada_test,y_ada_train,y_ada_test = train_test_split(x_ada,y_ada,test_size=0.3,random_state=1)

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

scaler = StandardScaler()

x_ada_train = scaler.fit_transform(x_ada_train)
x_ada_test = scaler.transform(x_ada_test)

from sklearn.model_selection import GridSearchCV
params = {"n_estimators":[100,200,300,400,500],
          "learning_rate": [1,1.25,1.5,1.75,2],
          "algorithm" : ["SAMME.R","SAMME"],
          }


clf_grid_cv = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=100))


grid_search = GridSearchCV(estimator=clf_grid_cv, param_grid=params, cv=5, verbose=3)
grid_search.fit(x_ada_train,y_ada_train)

grid_search.best_params_

(grid_search.best_score_*100)

y_ada_pred = grid_search.predict(x_ada_test)

from sklearn.metrics import roc_curve, auc

y_ada_pred_score = grid_search.predict_proba(x_ada_test)

y_ada_pred_score.min()

y_ada_pred_score.max()

# Evaluate training score
train_score = grid_search.score(x_ada_train, y_ada_train)

# Evaluate test score
test_score = grid_search.score(x_ada_test, y_ada_test)

print("Training Score: ", train_score)
print("Test Score: ", test_score)

# Cross-validation results
cv_results = grid_search.cv_results_

# Mean cross-validation scores
mean_test_scores = cv_results['mean_test_score']
std_test_scores = cv_results['std_test_score']

print("Mean Cross-Validation Scores: ", mean_test_scores)
print("Standard Deviation of Cross-Validation Scores: ", std_test_scores)

import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    grid_search.best_estimator_, x_ada_train, y_ada_train, cv=5, n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy')

train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.figure()
plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1,
                 color="r")
plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")
plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
         label="Training score")
plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
         label="Cross-validation score")

plt.xlabel("Training examples")
plt.ylabel("Score")
plt.title("Learning Curves")
plt.legend(loc="best")
plt.grid()
plt.show()





